{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code to generate some of the files used by our project website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "# Initial Spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import explode\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import lit, col, to_date\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.functions import stddev\n",
    "from pyspark.sql.functions import count, countDistinct, concat, sum\n",
    "from pyspark.sql.functions import percentile_approx\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"/Users/giacomoorsi/MEGAsync Downloads/Trenitalia-GenMar2023\"\n",
    "file = \"all.parquet\"\n",
    "\n",
    "SAVE_COMPUTATIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"Trenitalia\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# set driver memory to 4GB\n",
    "spark.sparkContext._conf.setAll([('spark.driver.memory', '4g')])\n",
    "\n",
    "# get sc \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8316723\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(os.path.join(DATA_FOLDER, \"parquet\", file))\n",
    "print(\"Number of rows: {}\".format(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset of the stops\n",
    "stops = spark.read.csv(os.path.join(DATA_FOLDER, \"stops.csv\"), header=True, inferSchema=True)\n",
    "\n",
    "stops_column_renamer = {\n",
    "    \"name\": \"stop_name\",\n",
    "    \"lat\": \"stop_lat\",\n",
    "    \"lon\": \"stop_lon\",\n",
    "    \"station_id\": \"stop_id\", \n",
    "    \"name_short\": \"stop_name_short\",\n",
    "    \"id_region\": \"stop_id_region\",\n",
    "}\n",
    "\n",
    "for k, v in stops_column_renamer.items():\n",
    "    stops = stops.withColumnRenamed(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days:  90\n",
      "First date:  2023-01-01\n",
      "Last date:  2023-03-31\n",
      "Number of trains:  11496\n",
      "Number of stops:  2291\n",
      "Number of train classes:  11\n"
     ]
    }
   ],
   "source": [
    "# number of days\n",
    "print(\"Number of days: \", df.select(\"date\").distinct().count())\n",
    "\n",
    "# first date\n",
    "print(\"First date: \", df.select(\"date\").distinct().orderBy(\"date\").first().asDict()[\"date\"])\n",
    "\n",
    "# last date\n",
    "print(\"Last date: \", df.select(\"date\").distinct().orderBy(\"date\", ascending=False).first().asDict()[\"date\"])\n",
    "\n",
    "# number of trains\n",
    "print(\"Number of trains: \", df.select(\"train_number\").distinct().count())\n",
    "\n",
    "# number of stops\n",
    "print(\"Number of stops: \", df.select(\"stop_name\").distinct().count())\n",
    "\n",
    "# number of train classes\n",
    "print(\"Number of train classes: \", df.select(\"train_class\").distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_arrival_stop_name', 'train_class', 'train_cn', 'train_dl', 'train_number', 'train_arrival_time', 'oae', 'train_oaz', 'train_od', 'train_oo', 'train_departure_time', 'train_ope', 'train_opz', 'train_departure_stop_name', 'train_pr', 'train_arrival_delay', 'train_departure_delay', 'sea', 'train_sep', 'train_sub', 'day', 'month', 'year', 'date', 'stop_name', 'stop_arrival_time', 'stop_departure_time', 'stop_arrival_delay', 'stop_departure_delay']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preprocessing\n",
    "As step of preprocessing, we remove all delays that are anomalous, i.e. they are not in the range [-100, 300] minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values for column oae: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values for column train_oaz: 106676\n",
      "Distinct values for column train_od: 289\n",
      "Distinct values for column train_oo: 300\n",
      "Distinct values for column train_cn: 228\n",
      "Distinct values for column train_dl: 1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values for column train_ope: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values for column train_opz: 100309\n",
      "Distinct values for column train_pr: 1\n",
      "Distinct values for column sea: 9\n",
      "Distinct values for column train_sep: 10\n",
      "Distinct values for column train_sub: 4\n"
     ]
    }
   ],
   "source": [
    "interesting_columns = ['oae', 'train_oaz', \"train_od\", \"train_oo\", \"train_cn\", \"train_dl\", \"train_ope\", \"train_opz\", \"train_pr\", \"sea\", \"train_sep\", \"train_sub\" ]\n",
    "\n",
    "# for each of the interesting_columns compute and show the distinct values\n",
    "for c in interesting_columns:\n",
    "    print(\"Distinct values for column {}: {}\".format(c, df.select(c).distinct().count()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all values of delays that are not in the range [-100, 300] if they are numerical\n",
    "MIN_DELAY = -100\n",
    "MAX_DELAY = 300\n",
    "df = df.filter((col(\"stop_arrival_delay\").cast(\"double\").isNull()) | (col(\"stop_arrival_delay\").cast(\"double\") >= MIN_DELAY) & (col(\"stop_arrival_delay\").cast(\"double\") <= MAX_DELAY))\n",
    "\n",
    "# for trains that have a non-null `train_sub`, we replace `train_class` with `train_sub`\n",
    "# NOTE: `train_sub` contains the category of high speed train (e.g. \"FR\", \"FB\", \"FA\" which stand for Frecciarossa, Frecciabianca, Frecciargento)\n",
    "# When a train is high speed, `train_class` is empty, apart from one case, which is the FrecciaRossa Milano -> Paris where the train_class is EC (EuroCity)\n",
    "# We replace that with FR (FrecciaRossa)\n",
    "df = df.withColumn(\"train_class\", F.when(col(\"train_sub\").isNotNull(), col(\"train_sub\")).otherwise(col(\"train_class\")))\n",
    "\n",
    "# remove all the trains that are not in the following classes\n",
    "KEEP_TRAIN_CLASSES = [\"IC\", \"ICN\", \"REG\", \"\", \"EC\", \"FA\", \"FB\", \"FR\"]\n",
    "\n",
    "df = df.filter(col(\"train_class\").isin(KEEP_TRAIN_CLASSES))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Statistics for each station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each distinct station, we want to obtain: \n",
    "1. Station name\n",
    "2. Latitude, longitude\n",
    "3. Average arrival delay\n",
    "4. Median arrival delay\n",
    "5. % of trains with delay > 3\n",
    "6. % of trains with delay > 5\n",
    "7. % of trains with delay > 10\n",
    "8. Number of distinct train numbers that stopped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column True if train had > 3 minutes of delay\n",
    "data_stop = df.join(stops, on=\"stop_name\", how=\"inner\")\n",
    "\n",
    "\n",
    "data_stop = data_stop \\\n",
    "    .filter(col(\"stop_arrival_delay\").cast(\"double\").isNotNull()) \\\n",
    "    .withColumn(\"stop_arrival_delay_double\", col(\"stop_arrival_delay\").cast(\"double\")) \\\n",
    "    .drop(\"stop_arrival_delay\") \\\n",
    "    .withColumnRenamed(\"stop_arrival_delay_double\", \"stop_arrival_delay\") \\\n",
    "    .withColumn(\"3m_delay\", col(\"stop_arrival_delay\") > 3)\\\n",
    "    .withColumn(\"5m_delay\", col(\"stop_arrival_delay\") > 5)\\\n",
    "    .withColumn(\"10m_delay\", col(\"stop_arrival_delay\") > 10)\\\n",
    "    .withColumn(\"day_of_week\", F.date_format(F.col(\"date\"), \"E\"))\\\n",
    "    .withColumn(\"train_id\", concat(col(\"train_class\"), col(\"train_number\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 437:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops:  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops: \", data_stop_stat.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops in (lat,long) dataset:  2961\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops in (lat,long) dataset: \", stops.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 447:==============>                                          (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops in final dataset:  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of stops in final dataset: \", data_stop_stat.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_THRESHOLD_STOP = 12\n",
    "# we keep only stops that had at least one train per week, over the 3 months analyzed\n",
    "data_stop_stat = data_stop_stat.filter(col(\"count_trains\") >= MIN_THRESHOLD_STOP)\n",
    "\n",
    "# we filter out stops without lat/lon\n",
    "data_stop_stat = data_stop_stat.filter(col(\"stop_lat\").isNotNull() & col(\"stop_lon\").isNotNull())\n",
    "\n",
    "data_stop_stat = data_stop_stat.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>avg_arrival_delay</th>\n",
       "      <th>median_arrival_delay</th>\n",
       "      <th>count_trains</th>\n",
       "      <th>count_stops</th>\n",
       "      <th>count_3m_delay</th>\n",
       "      <th>count_5m_delay</th>\n",
       "      <th>count_10m_delay</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBASANTA</td>\n",
       "      <td>1.251249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1401</td>\n",
       "      <td>205</td>\n",
       "      <td>131</td>\n",
       "      <td>79</td>\n",
       "      <td>40.128801</td>\n",
       "      <td>8.817733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBIATEGRASSO</td>\n",
       "      <td>2.978809</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>3728</td>\n",
       "      <td>1105</td>\n",
       "      <td>596</td>\n",
       "      <td>209</td>\n",
       "      <td>45.400631</td>\n",
       "      <td>8.921305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACQUAVIVA</td>\n",
       "      <td>3.013732</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2039</td>\n",
       "      <td>721</td>\n",
       "      <td>327</td>\n",
       "      <td>61</td>\n",
       "      <td>37.570258</td>\n",
       "      <td>13.674927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACQUAVIVA DELLE FONTI</td>\n",
       "      <td>1.041216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2402</td>\n",
       "      <td>158</td>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40.892806</td>\n",
       "      <td>16.839826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACQUEDOLCI-S.FRATELLO</td>\n",
       "      <td>0.272120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1198</td>\n",
       "      <td>93</td>\n",
       "      <td>57</td>\n",
       "      <td>22</td>\n",
       "      <td>38.058459</td>\n",
       "      <td>14.587597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CASTELNUOVO BERARDENGA</td>\n",
       "      <td>2.669107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30</td>\n",
       "      <td>1366</td>\n",
       "      <td>342</td>\n",
       "      <td>156</td>\n",
       "      <td>35</td>\n",
       "      <td>43.306882</td>\n",
       "      <td>11.484912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CASTELVECCHIO PASCOLI</td>\n",
       "      <td>3.582547</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>848</td>\n",
       "      <td>345</td>\n",
       "      <td>158</td>\n",
       "      <td>17</td>\n",
       "      <td>44.090070</td>\n",
       "      <td>10.455061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>CASTELVETRO</td>\n",
       "      <td>1.780123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1137</td>\n",
       "      <td>185</td>\n",
       "      <td>99</td>\n",
       "      <td>42</td>\n",
       "      <td>45.100095</td>\n",
       "      <td>9.982181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>CASTIGLION FIORENTINO</td>\n",
       "      <td>3.584505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54</td>\n",
       "      <td>3769</td>\n",
       "      <td>1420</td>\n",
       "      <td>824</td>\n",
       "      <td>259</td>\n",
       "      <td>43.340750</td>\n",
       "      <td>11.914362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>CATANZARO LIDO</td>\n",
       "      <td>3.165400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51</td>\n",
       "      <td>3289</td>\n",
       "      <td>1123</td>\n",
       "      <td>614</td>\n",
       "      <td>205</td>\n",
       "      <td>38.821788</td>\n",
       "      <td>16.612975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stop_name  avg_arrival_delay  median_arrival_delay  \\\n",
       "0                ABBASANTA           1.251249                   0.0   \n",
       "1            ABBIATEGRASSO           2.978809                   2.0   \n",
       "2                ACQUAVIVA           3.013732                   2.0   \n",
       "3    ACQUAVIVA DELLE FONTI           1.041216                   1.0   \n",
       "4    ACQUEDOLCI-S.FRATELLO           0.272120                   0.0   \n",
       "..                     ...                ...                   ...   \n",
       "95  CASTELNUOVO BERARDENGA           2.669107                   2.0   \n",
       "96   CASTELVECCHIO PASCOLI           3.582547                   3.0   \n",
       "97             CASTELVETRO           1.780123                   1.0   \n",
       "98   CASTIGLION FIORENTINO           3.584505                   2.0   \n",
       "99          CATANZARO LIDO           3.165400                   2.0   \n",
       "\n",
       "    count_trains  count_stops  count_3m_delay  count_5m_delay  \\\n",
       "0             29         1401             205             131   \n",
       "1             57         3728            1105             596   \n",
       "2             30         2039             721             327   \n",
       "3             36         2402             158              74   \n",
       "4             18         1198              93              57   \n",
       "..           ...          ...             ...             ...   \n",
       "95            30         1366             342             156   \n",
       "96            15          848             345             158   \n",
       "97            18         1137             185              99   \n",
       "98            54         3769            1420             824   \n",
       "99            51         3289            1123             614   \n",
       "\n",
       "    count_10m_delay   stop_lat   stop_lon  \n",
       "0                79  40.128801   8.817733  \n",
       "1               209  45.400631   8.921305  \n",
       "2                61  37.570258  13.674927  \n",
       "3                35  40.892806  16.839826  \n",
       "4                22  38.058459  14.587597  \n",
       "..              ...        ...        ...  \n",
       "95               35  43.306882  11.484912  \n",
       "96               17  44.090070  10.455061  \n",
       "97               42  45.100095   9.982181  \n",
       "98              259  43.340750  11.914362  \n",
       "99              205  38.821788  16.612975  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stop_pandas = data_stop_stat.toPandas()\n",
    "data_stop_pandas.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv\n",
    "if SAVE_COMPUTATIONS:\n",
    "    data_stop_pandas.to_csv((\"dataset_generated/data_stop/data_stop.csv\"), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Statistics for each day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"day_of_week\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file for each day of week with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for day in data_stop_stat_pandas[\"day_of_week\"].unique():\n",
    "        data_stop_stat_pandas[data_stop_stat_pandas[\"day_of_week\"] == day].to_csv((\"dataset_generated/data_stop/data_stop_{}.csv\".format(day)), index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. Statistics for each train type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"train_class\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|           stop_name|train_class| avg_arrival_delay|median_arrival_delay|count_trains|count_stops|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|\n",
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "|           ABBASANTA|        REG| 1.251249107780157|                 0.0|          29|       1401|           205|           131|             79|40.128801| 8.817733|\n",
      "|ACQUAVIVA DELLE F...|        REG|1.0412156536219817|                 1.0|          36|       2402|           158|            74|             35|40.892806|16.839826|\n",
      "|         ACQUI TERME|        REG| 3.531089978054133|                 3.0|          41|       2734|           994|           453|            103| 44.67407| 8.474482|\n",
      "|AGROPOLI CASTELLA...|         FR| 7.104651162790698|                 3.0|           2|        172|            86|            61|             34|40.351521|15.002053|\n",
      "|AGROPOLI CASTELLA...|        ICN| 5.591549295774648|                 2.0|           2|         71|            27|            23|             13|40.351521|15.002053|\n",
      "|             AIRASCA|        REG| 4.418723404255319|                 4.0|          46|       3525|          2073|          1247|            134|44.928093| 7.483536|\n",
      "|              AIRUNO|        REG|3.0874976428436733|                 1.0|          69|       5303|          1339|           778|            275|45.754086| 9.422066|\n",
      "|                 ALA|        REG| 4.321287779237845|                 3.0|          69|       4566|          2119|          1360|            448|45.760087|10.996775|\n",
      "|                ALBA|        REG|0.5326170376055257|                 0.0|          18|       1303|           104|            34|             15|44.697713| 8.030629|\n",
      "|  ALBAIRATE VERMEZZO|        REG| 1.008749189889825|                 0.0|          95|       6172|          1067|           631|            279|     null|     null|\n",
      "|     ALBATE-TRECALLO|        REG| 2.538695917123705|                 2.0|          22|       1641|           396|           160|             19|45.777391| 9.095752|\n",
      "|            ALBISOLA|        REG|1.9523715803975594|                 1.0|         101|       5081|           798|           428|            139| 44.33469| 8.512092|\n",
      "|         ALESSANDRIA|         FB|2.7425149700598803|                 0.0|           2|        167|            49|            35|             15|44.909091| 8.606498|\n",
      "|         ALESSANDRIA|        REG|1.1352555701179554|                 1.0|         121|       7630|          1794|          1020|            287|44.909091| 8.606498|\n",
      "|      ALICE BELCOLLE|        REG|0.9135538954108858|                 0.0|          16|        937|            36|            18|              7|44.722636| 8.440076|\n",
      "|          ALI` TERME|        REG| 2.331540013449899|                 1.0|          51|       2974|           721|           458|            162|38.013952|15.435184|\n",
      "|              ALTARE|        REG|1.3159851301115242|                 0.0|          11|        807|            77|            61|             32|44.336169| 8.332753|\n",
      "|             AMANTEA|        REG|0.8201603665521191|                 0.0|          26|       1746|           201|           118|             52|39.134353|16.068448|\n",
      "|   AMOROSI MELIZZANO|         FA|33.333333333333336|                30.0|           1|          3|             3|             3|              3|41.173509|14.470759|\n",
      "|   AMOROSI MELIZZANO|         IC|              10.5|                 7.0|           1|          2|             2|             2|              1|41.173509|14.470759|\n",
      "+--------------------+-----------+------------------+--------------------+------------+-----------+--------------+--------------+---------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat.show()\n",
    "\n",
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file for each day of week with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for train_class in data_stop_stat_pandas[\"train_class\"].unique():\n",
    "        data_stop_stat_pandas[data_stop_stat_pandas[\"train_class\"] == train_class].to_csv((\"dataset_generated/data_stop/data_stop_class_{}.csv\".format(train_class)), index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d. Statistics for each week day and train type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stop_stat = data_stop.groupBy(\"stop_name\", \"train_class\", \"day_of_week\") \\\n",
    "    .agg(\n",
    "        F.avg(\"stop_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"stop_arrival_delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"train_id\").alias(\"count_trains\"),\n",
    "        F.count(\"train_id\").alias(\"count_stops\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_stop_stat_pandas = data_stop_stat.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each combination of weekday and train_class, create a file with the statistics\n",
    "if SAVE_COMPUTATIONS:\n",
    "    for day in data_stop_stat_pandas[\"day_of_week\"].unique():\n",
    "        for train_class in data_stop_stat_pandas[\"train_class\"].unique():\n",
    "            data_stop_stat_pandas[(data_stop_stat_pandas[\"day_of_week\"] == day) & (data_stop_stat_pandas[\"train_class\"] == train_class)].to_csv((\"dataset_generated/data_stop/data_stop_mix_{}_{}.csv\".format(day, train_class)), index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train statistics\n",
    "For each train, the goal is to store the following information:\n",
    "1. Ordered list of the stations it stopped at\n",
    "2. For each destination: \n",
    "    1. Average arrival delay\n",
    "    2. Median arrival delay\n",
    "    3. % of trains with delay > 3\n",
    "    4. % of trains with delay > 5\n",
    "    5. % of trains with delay > 10\n",
    "    6. Number of days it stopped at the destination\n",
    "\n",
    "To avoid keeping statistics for temporary stops and trains, we remove: \n",
    "- Trains that appeared in the dataset only <10  distinct times\n",
    "- Stops for a train, that appeared less than 20% of the dates that the train appeared in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we add coordinates to each stop, so that we can drop stops for which we don't have the coordinates\n",
    "df_trains = df.join(stops, on=\"stop_name\", how=\"inner\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. For each train, we obtain the statistics of each of its stops, removing the stops that appear less than 20% of the dates that the train appeared in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_arrival_stop_name', 'train_class', 'train_cn', 'train_dl', 'train_number', 'train_arrival_time', 'oae', 'train_oaz', 'train_od', 'train_oo', 'train_departure_time', 'train_ope', 'train_opz', 'train_departure_stop_name', 'train_pr', 'train_arrival_delay', 'train_departure_delay', 'sea', 'train_sep', 'train_sub', 'day', 'month', 'year', 'date', 'stop_name', 'stop_arrival_time', 'stop_departure_time', 'stop_arrival_delay', 'stop_departure_delay']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, we have to keep in mind that the same train number can refer to multiple trains, so we also have to group by the destination stop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 488:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|train_arrival_stop_name|\n",
      "+-----------------------+\n",
      "|           ROMA TERMINI|\n",
      "|         COMO NORD LAGO|\n",
      "+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# this shows that there's multiple trains with the same number\n",
    "df \\\n",
    "    .filter((F.col(\"train_class\") == \"REG\") & (F.col(\"train_number\") == \"4113\"))\\\n",
    "    .select(\"train_arrival_stop_name\")\\\n",
    "    .distinct()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "|           stop_name|train_arrival_stop_name|train_class|train_cn|train_dl|train_number|train_arrival_time| oae| train_oaz|train_od|train_oo|train_departure_time|train_ope| train_opz|train_departure_stop_name|train_pr|train_arrival_delay|train_departure_delay| sea|train_sep|train_sub|day|month|year|      date|stop_arrival_time|stop_departure_time|stop_arrival_delay|stop_departure_delay|stop_id| stop_name_short| stop_lat| stop_lon|stop_id_region|delay|stop_time|\n",
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "|          CISTERNINO|                  LECCE|        REG|    null|    null|       34445|        1674864180|null|1674864180|    null|    null|          1674857400|     null|1674857400|            BARI CENTRALE|    null|                  2|                    3|null|     null|     null| 28|   01|2023|2023-01-28|       1674860400|         1674860460|              n.d.|                   5| S11131|      Cisternino|40.816652|17.456899|          16.0| n.d.|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       33067|        1679955420|null|1679955420|    null|    null|          1679951160|     null|1679951160|                    LECCO|    null|                 -2|                    1|null|     null|     null| 28|   03|2023|2023-03-28|       1679954400|         1679954460|                -1|                   0| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -1|    00:00|\n",
      "|             VIGNATE|                BERGAMO|        REG|    null|    null|        2247|        1676418600|null|1676418600|    null|    null|          1676414400|     null|1676414400|          MILANO CENTRALE|    null|                  1|                    1|null|     null|     null| 15|   02|2023|2023-02-15|       1676415600|         1676415660|              n.d.|                   1| S01704|         Vignate|45.493946| 9.374083|           1.0| n.d.|    00:00|\n",
      "|          CISTERNINO|                  LECCE|        REG|    null|    null|       34445|        1678320180|null|1678320180|    null|    null|          1678313400|     null|1678313400|            BARI CENTRALE|    null|                 10|                    4|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316460|              n.d.|                  12| S11131|      Cisternino|40.816652|17.456899|          16.0| n.d.|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       33067|        1679008620|null|1679008620|    null|    null|          1679004360|     null|1679004360|                    LECCO|    null|                 -3|                    0|null|     null|     null| 17|   03|2023|2023-03-17|       1679007600|         1679007660|                -1|                   0| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -1|    00:00|\n",
      "|           MACCARESE|          CIVITAVECCHIA|        REG|    null|    null|       12554|        1678319040|null|1678319040|    null|    null|          1678314420|     null|1678314420|             ROMA TERMINI|    null|                  1|                    0|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316460|                 1|                   2| S08020|       Maccarese|41.879372| 12.23695|           5.0|    1|    00:00|\n",
      "|      LOCATE TRIULZI|                  PAVIA|        REG|    null|    null|       24383|        1674688860|null|1674688860|    null|    null|          1674685500|     null|1674685500|        MILANO BOVISA FNM|    null|                  6|                    3|null|     null|     null| 26|   01|2023|2023-01-26|       1674687600|         1674687660|              n.d.|                n.d.| S01801|  Locate Triulzi| 45.35973| 9.221398|           1.0| n.d.|    00:00|\n",
      "|           MACCARESE|          CIVITAVECCHIA|        REG|    null|    null|       12554|        1679957040|null|1679957040|    null|    null|          1679952420|     null|1679952420|             ROMA TERMINI|    null|                  1|                    0|null|     null|     null| 28|   03|2023|2023-03-28|       1679954400|         1679954460|                 4|                   5| S08020|       Maccarese|41.879372| 12.23695|           5.0|    4|    00:00|\n",
      "|MILANO GRECO PIRELLI|   MILANO PORTA GARI...|        REG|    null|    null|       24889|        1674860880|null|1674860880|    null|    null|          1674857160|     null|1674857160|                    LECCO|    null|                 -2|                    0|null|     null|     null| 28|   01|2023|2023-01-28|       1674860400|         1674860460|                -2|                   1| S01326|MI Greco Pirelli| 45.51272| 9.214456|           1.0|   -2|    00:00|\n",
      "|              VARESE|                 STABIO|        REG|    null|    null|       25592|        1678317720|null|1678317720|    null|    null|          1678313940|     null|1678313940|     MALPENSA AEROPORT...|    null|                 -1|                    1|null|     null|     null| 09|   03|2023|2023-03-09|       1678316400|         1678316760|                 1|                   1| S01205|          Varese|45.816201| 8.833089|           1.0|    1|    00:00|\n",
      "+--------------------+-----------------------+-----------+--------+--------+------------+------------------+----+----------+--------+--------+--------------------+---------+----------+-------------------------+--------+-------------------+---------------------+----+---------+---------+---+-----+----+----------+-----------------+-------------------+------------------+--------------------+-------+----------------+---------+---------+--------------+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first we create a new column with the delay in minutes. For all stops this has to be the arrival_delay apart for the first stop of each train, for which it has to be the departure_delay\n",
    "df_trains1 = df_trains.withColumn(\"delay\", F.when(F.col(\"stop_arrival_delay\") == \"N\", F.col(\"stop_departure_delay\")).otherwise(F.col(\"stop_arrival_delay\")))\n",
    "\n",
    "# second, add a column \"stop_arrival_time\", which is the arrival time at the stop, in the format \"HH:MM\"\n",
    "# if the stop is the first stop of the train, then the stop_arrival_time is the departure time of the train\n",
    "\n",
    "df_trains1 = df_trains1\\\n",
    "    .withColumn(\"stop_time\", F.when(F.col(\"stop_arrival_time\") == 0, F.col(\"stop_departure_time\")).otherwise(F.col(\"stop_arrival_time\"))) \\\n",
    "    .withColumn(\"stop_time\", F.date_format(F.col(\"stop_time\").cast(\"timestamp\"), \"HH:mm\"))\n",
    "\n",
    "    \n",
    "\n",
    "df_trains1.orderBy(\"stop_time\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "|train_departure_stop_name|train_arrival_stop_name|train_class|train_number|      date|stop_id|stop_time|     stop_name|stop_name_short| stop_lat| stop_lon|stop_id_region|3m_delay|5m_delay|10m_delay|delay|\n",
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "|           FIRENZE S.M.N.|           ROMA TERMINI|        REG|        4113|2023-02-06| S06421|    21:14|FIRENZE S.M.N.| Firenze S.M.N.|43.776893|11.247373|          13.0|       1|       1|        1| 19.0|\n",
      "+-------------------------+-----------------------+-----------+------------+----------+-------+---------+--------------+---------------+---------+---------+--------------+--------+--------+---------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the delay to double and add a counter if the train was 3m, 5m, 10m late\n",
    "# add a column with the number of distinct dates for each train\n",
    "# remove the column if the delay cannot be casted to double\n",
    "df_trains2 = df_trains1 \\\n",
    "    .withColumn(\"delay\", F.col(\"delay\").cast(\"double\")) \\\n",
    "    .filter(F.col(\"delay\").isNotNull()) \\\n",
    "    .withColumn(\"3m_delay\", F.when(F.col(\"delay\") >= 3, 1).otherwise(0)) \\\n",
    "    .withColumn(\"5m_delay\", F.when(F.col(\"delay\") >= 5, 1).otherwise(0)) \\\n",
    "    .withColumn(\"10m_delay\", F.when(F.col(\"delay\") >= 10, 1).otherwise(0))\\\n",
    "    .select(\"train_departure_stop_name\", \"train_arrival_stop_name\", \"train_class\", \"train_number\", \"date\", \"stop_id\", \"stop_time\", \"stop_name\", \"stop_name_short\", \"stop_lat\", \"stop_lon\", \"stop_id_region\", \"3m_delay\", \"5m_delay\", \"10m_delay\", \"delay\")\n",
    "\n",
    "df_trains2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For each train, we obtain the statistics of each of its stops, removing the stops that appear less than 20% of the dates that the train appeared in the dataset\n",
    "# add the stop incremental number\n",
    "df_trains_stat1 = df_trains2.groupBy(\"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\", \"stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.percentile_approx(\"delay\", 0.5).alias(\"median_arrival_delay\"),\n",
    "        F.countDistinct(\"date\").alias(\"count_dates_stop\"),\n",
    "        F.min(\"date\").alias(\"first_date\"),\n",
    "        F.max(\"date\").alias(\"last_date\"),\n",
    "        F.sum(F.col(\"3m_delay\").cast(\"long\")).alias(\"count_3m_delay\"),\n",
    "        F.sum(F.col(\"5m_delay\").cast(\"long\")).alias(\"count_5m_delay\"),\n",
    "        F.sum(F.col(\"10m_delay\").cast(\"long\")).alias(\"count_10m_delay\"),\n",
    "        F.first(\"stop_lat\").alias(\"stop_lat\"),\n",
    "        F.first(\"stop_lon\").alias(\"stop_lon\"),\n",
    "        F.mode(\"stop_time\").alias(\"stop_time\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts how many distinct dates a train apparead in the dataset\n",
    "# and filter out trains that didn't appear at least 4 times a month (12 times in total)\n",
    "MIN_THRESHOLD_TRAIN = 12\n",
    "\n",
    "df_trains_counts = df_trains2.groupBy(\"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\") \\\n",
    "    .agg(\n",
    "        F.countDistinct(\"date\").alias(\"count_dates_train\")\n",
    "    ) \\\n",
    "    .filter(F.col(\"count_dates_train\") >= MIN_THRESHOLD_TRAIN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store the data we create a mapper from a (train_class, train_number, train_arrival_stop_name) to an id, and we store the information of that train on a file with the name of the id. To do that, we add a column which is a monotonic increasing id, and we use that as the id of that train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trains_counts = df_trains_counts \\\n",
    "    .withColumn(\"train_id\", F.monotonically_increasing_id()) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two datasets and filter out stations that appear in less than 20% of the dates\n",
    "df_trains_stat2 = df_trains_stat1.join(df_trains_counts, on=[\"train_class\", \"train_number\", \"train_arrival_stop_name\", \"train_departure_stop_name\"], how=\"inner\") \\\n",
    "    .filter(F.col(\"count_dates_stop\") >= F.col(\"count_dates_train\") * 0.2) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 502:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "|train_class|train_number|train_arrival_stop_name|train_departure_stop_name|      stop_name| avg_arrival_delay|median_arrival_delay|count_dates_stop|first_date| last_date|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|stop_time|count_dates_train|train_id|\n",
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|         LATINA| 9.083333333333334|                 4.0|              12|2023-01-21|2023-02-01|             7|             5|              2|41.538372|12.945888|    13:58|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|NAPOLI CENTRALE|12.583333333333334|                 5.0|              12|2023-01-21|2023-02-01|             9|             7|              4|40.852933|14.272908|    12:18|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|    BATTIPAGLIA|1.6666666666666667|                 1.0|              12|2023-01-21|2023-02-01|             3|             0|              0|40.605789| 14.98324|    11:27|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|        SALERNO| 4.083333333333333|                 2.0|              12|2023-01-21|2023-02-01|             6|             3|              1|40.675137|14.772822|    11:38|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|   ROMA TERMINI| 9.833333333333334|                 0.0|              12|2023-01-21|2023-02-01|             4|             2|              2|41.900636|12.502026|    14:34|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|   FORMIA-GAETA|13.916666666666666|                 8.0|              12|2023-01-21|2023-02-01|            12|             9|              3|41.258773|13.605996|    13:20|               12|      35|\n",
      "|         IC|         700|           ROMA TERMINI|              BATTIPAGLIA|         AVERSA|             10.25|                 3.0|              12|2023-01-21|2023-02-01|             7|             5|              3|40.973323|14.218578|    12:47|               12|      35|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|        PIADENA| 5.213333333333333|                 5.0|              75|2023-01-02|2023-03-31|            53|            39|             10|45.127608|10.369962|    08:30|               75|      20|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|  CASTELLUCCHIO|2.7733333333333334|                 2.0|              75|2023-01-02|2023-03-31|            37|             5|              1|45.144293| 10.64749|    08:03|               75|      20|\n",
      "|        REG|       10004|                CREMONA|                  MANTOVA|        CREMONA| 5.733333333333333|                 5.0|              75|2023-01-02|2023-03-31|            54|            39|             15|45.143215|10.017951|    08:49|               75|      20|\n",
      "+-----------+------------+-----------------------+-------------------------+---------------+------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trains_stat2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "|train_class|train_number|train_arrival_stop_name|train_departure_stop_name|           stop_name|   avg_arrival_delay|median_arrival_delay|count_dates_stop|first_date| last_date|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|stop_time|count_dates_train|train_id|stop_number|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|              SAVONA|  2.5238095238095237|                 2.0|              63|2023-01-02|2023-03-31|            13|             4|              1|44.306892| 8.470259|    06:28|               63|       0|          1|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|       GENOVA VOLTRI| -1.3650793650793651|                -3.0|              63|2023-01-02|2023-03-31|             9|             5|              0|44.428467| 8.758163|    06:48|               63|       0|          2|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA SESTRI PON...|  0.5873015873015873|                 0.0|              63|2023-01-02|2023-03-31|             5|             2|              0|44.422374| 8.847707|    07:02|               63|       0|          3|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA SAMPIERDARENA|  -2.238095238095238|                -3.0|              63|2023-01-02|2023-03-31|             2|             0|              0|44.413102| 8.887271|    07:13|               63|       0|          4|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|   GENOVA P.PRINCIPE|  1.3650793650793651|                 1.0|              63|2023-01-02|2023-03-31|             7|             6|              1|44.417784|   8.9207|    07:20|               63|       0|          5|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|     GENOVA BRIGNOLE| 0.38095238095238093|                 1.0|              63|2023-01-02|2023-03-31|             9|             2|              0|44.407213| 8.947553|    07:31|               63|       0|          6|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|GENOVA QUARTO DEI...|  1.7777777777777777|                 1.0|              63|2023-01-02|2023-03-31|            10|             5|              0|44.388607|  8.99597|    07:41|               63|       0|          7|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|        GENOVA NERVI|  2.0952380952380953|                 1.0|              63|2023-01-02|2023-03-31|            19|             5|              0|44.381271| 9.039895|    07:48|               63|       0|          8|\n",
      "|        REG|       22821|                  RECCO|                   SAVONA|               RECCO|-0.06349206349206349|                -1.0|              63|2023-01-02|2023-03-31|             8|             3|              0|44.361215| 9.146788|    08:08|               63|       0|          9|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|             SARONNO|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|45.625309| 9.030839|    19:53|               89|       1|          1|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|         SARONNO SUD|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    19:56|               89|       1|          2|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|              CESATE|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:00|               89|       1|          3|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|        BOLLATE NORD|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:07|               89|       1|          4|\n",
      "|        REG|         876|            M N CADORNA|                  SARONNO|      BOLLATE CENTRO|                 0.0|                 0.0|              89|2023-01-01|2023-03-31|             0|             0|              0|     null|     null|    20:09|               89|       1|          5|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|MILANO PORTA GARI...|  1.8153846153846154|                 1.0|              65|2023-01-02|2023-03-31|             9|             2|              2|45.484917| 9.187683|    21:46|               65|       2|          1|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|    RHO FIERA MILANO|  0.3230769230769231|                -1.0|              65|2023-01-02|2023-03-31|             6|             2|              1|45.521157| 9.088595|    21:56|               65|       2|          2|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|       BUSTO ARSIZIO|  -3.830769230769231|                -4.0|              65|2023-01-02|2023-03-31|             1|             1|              1|45.616164| 8.865031|    22:17|               65|       2|          3|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|           GALLARATE|             1.03125|                 1.0|              64|2023-01-02|2023-03-31|             6|             1|              1|45.659828| 8.798243|    22:23|               65|       2|          4|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|   CASORATE SEMPIONE|  1.6307692307692307|                 1.0|              65|2023-01-02|2023-03-31|             9|             2|              1|45.675075| 8.743954|    22:28|               65|       2|          5|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|      SOMMA LOMBARDO|  0.3076923076923077|                 0.0|              65|2023-01-02|2023-03-31|             7|             2|              1|45.686423| 8.712991|    22:32|               65|       2|          6|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|            VERGIATE| -0.1076923076923077|                -1.0|              65|2023-01-02|2023-03-31|             4|             1|              1|45.717119| 8.693187|    22:36|               65|       2|          7|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|       SESTO CALENDE|-0.13846153846153847|                -1.0|              65|2023-01-02|2023-03-31|             3|             3|              1|45.726241| 8.628135|    22:42|               65|       2|          8|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|         DORMELLETTO| 0.23076923076923078|                 0.0|              65|2023-01-02|2023-03-31|             6|             3|              1|  45.7233| 8.581906|    22:47|               65|       2|          9|\n",
      "|        REG|       10244|                  ARONA|     MILANO PORTA GARI...|               ARONA|-0.13846153846153847|                -1.0|              65|2023-01-02|2023-03-31|             5|             4|              1|45.755392| 8.559075|    22:54|               65|       2|         10|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|    PALERMO CENTRALE|            0.421875|                 0.0|              64|2023-01-02|2023-03-31|             1|             0|              0|38.109187|13.367515|    20:33|               64|       3|          1|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|     TERMINI IMERESE|              -2.625|                -3.0|              64|2023-01-02|2023-03-31|             0|             0|              0|37.980132|13.703631|    20:57|               64|       3|          2|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|             CEFALU`|           -0.859375|                -1.0|              64|2023-01-02|2023-03-31|             2|             1|              0| 38.03285|14.019526|    21:15|               64|       3|          3|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|SANTO STEFANO DI ...|           -2.171875|                -3.0|              64|2023-01-02|2023-03-31|             3|             1|              1| 38.01778| 14.35104|    21:42|               64|       3|          4|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|          S.AGATA M.|            -0.84375|                -2.0|              64|2023-01-02|2023-03-31|             9|             4|              2|38.073554|14.640622|    22:05|               64|       3|          5|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE| CAPO D`ORLANDO-NASO|            1.296875|                 1.0|              64|2023-01-02|2023-03-31|             9|             5|              2|38.157941|14.744844|    22:20|               64|       3|          6|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|PATTI-SAN PIERO P...|  2.4761904761904763|                 1.0|              63|2023-01-02|2023-03-31|            19|             7|              4|38.146905|14.975331|    22:37|               64|       3|          7|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|          BARCELLONA|  1.8548387096774193|                 1.0|              62|2023-01-02|2023-03-31|            14|             9|              3| 38.14918|15.212499|    22:49|               64|       3|          8|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|             MILAZZO|   2.161290322580645|                 1.0|              62|2023-01-02|2023-03-31|            18|            10|              2| 38.21195|15.244203|    22:55|               64|       3|          9|\n",
      "|        REG|        5368|       MESSINA CENTRALE|         PALERMO CENTRALE|    MESSINA CENTRALE|           -0.140625|                 0.0|              64|2023-01-02|2023-03-31|            13|             8|              1|38.184975|15.561278|    23:20|               64|       3|         10|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|              MODENA|  1.7916666666666667|                 2.0|              72|2023-01-02|2023-03-31|             8|             0|              0|44.654461|10.930373|    07:34|               72|       4|          1|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|       QUATTRO VILLE| 0.08333333333333333|                 0.0|              72|2023-01-02|2023-03-31|             3|             0|              0|     null|     null|    07:40|               72|       4|          2|\n",
      "|        REG|       22402|                  CARPI|                   MODENA|               CARPI| 0.09722222222222222|                 0.0|              72|2023-01-02|2023-03-31|             5|             2|              0|44.782919|10.891952|    07:50|               72|       4|          3|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|             SALERNO|  1.8426966292134832|                 1.0|              89|2023-01-01|2023-03-31|            22|             5|              2|40.675137|14.772822|    07:33|               89|       5|          1|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|              FRATTE|  2.5730337078651684|                 2.0|              89|2023-01-01|2023-03-31|            39|            10|              1|40.705637|14.778362|    07:43|               89|       5|          2|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|          PELLEZZANO|  3.5168539325842696|                 3.0|              89|2023-01-01|2023-03-31|            51|            19|              4|40.719928|14.777354|    07:51|               89|       5|          3|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|           BARONISSI|   2.101123595505618|                 2.0|              89|2023-01-01|2023-03-31|            31|            12|              2|40.743779| 14.77224|    08:00|               89|       5|          4|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|            FISCIANO|  1.4943820224719102|                 1.0|              89|2023-01-01|2023-03-31|            21|            10|              2|40.759095| 14.77486|    08:06|               89|       5|          5|\n",
      "|        REG|        5010|   MERCATO SAN SEVERINO|                  SALERNO|MERCATO SAN SEVERINO|  2.2247191011235956|                 2.0|              89|2023-01-01|2023-03-31|            31|            11|              2|40.783095|14.759749|    08:12|               89|       5|          6|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|     TERMINI IMERESE|  0.9733333333333334|                 1.0|              75|2023-01-02|2023-03-31|             5|             1|              0|37.980132|13.703631|    10:34|               75|       6|          1|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|        ALTAVILLA M.|               -0.76|                -1.0|              75|2023-01-02|2023-03-31|             1|             0|              0|38.048392|13.554421|    10:50|               75|       6|          2|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|            BAGHERIA|                1.32|                 1.0|              75|2023-01-02|2023-03-31|            11|             2|              0|38.089905|13.507215|    11:00|               75|       6|          3|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|  PALERMO BRANCACCIO|                1.12|                 1.0|              75|2023-01-02|2023-03-31|            11|             2|              0|38.093141|13.392508|    11:12|               75|       6|          4|\n",
      "|        REG|       21813|       PALERMO CENTRALE|          TERMINI IMERESE|    PALERMO CENTRALE|  1.1866666666666668|                 1.0|              75|2023-01-02|2023-03-31|             9|             2|              0|38.109187|13.367515|    11:17|               75|       6|          5|\n",
      "|        REG|       19874|                  MELFI|         POTENZA CENTRALE|    POTENZA CENTRALE|  2.3421052631578947|                 1.0|              76|2023-01-02|2023-03-31|             5|             3|              3|40.629469|15.806808|    07:15|               76|       7|          1|\n",
      "|        REG|       19874|                  MELFI|         POTENZA CENTRALE|   POTENZA SUPERIORE| 0.14473684210526316|                -1.0|              76|2023-01-02|2023-03-31|             5|             3|              3| 40.64586|15.800966|    07:21|               76|       7|          2|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------------+--------------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+--------+-----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# add the stop incremental number\n",
    "df_trains_stat3 = df_trains_stat2 \\\n",
    "    .withColumn(\"stop_number\", F.row_number().over(Window.partitionBy(\"train_id\").orderBy(\"stop_time\"))) \\\n",
    "    .sort(\"train_id\", \"stop_number\") \\\n",
    "    .cache()\n",
    "\n",
    "\n",
    "df_trains_stat3.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# now we store df_trains_stat2 in a csv file, partitioned by the column \"train_id\". \n",
    "# Each \"train_id\" should have a single file, and each file should contain the statistics of all the stops of the train\n",
    "\n",
    "# remove folder if it already exists\n",
    "\n",
    "if SAVE_COMPUTATIONS : \n",
    "    import shutil\n",
    "    shutil.rmtree(\"dataset_generated/data_train_stat\")\n",
    "\n",
    "\n",
    "    df_trains_stat3 \\\n",
    "        .repartition(\"train_id\") \\\n",
    "        .write \\\n",
    "        .partitionBy(\"train_id\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(\"dataset_generated/data_train_stat/data_train_stat.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read from file\n",
    "# df_trains_stat3 = spark.read.option(\"header\", \"true\").csv(\"dataset_generated/data_train_stat/data_train_stat.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to elaborate some general stastistics about a train, and store a dataset which is an index of the train ids, and the statistics of that train.\n",
    "\n",
    "The aggregated statistics that we want to store are: \n",
    "1. Average arrival delay at each destination\n",
    "2. Median arrival delay at each destination\n",
    "3. % of trains with delay > 3 at each destination\n",
    "4. % of trains with delay > 5 at each destination\n",
    "5. % of trains with delay > 10 at each destination\n",
    "6. Number of days the train ran\n",
    "7. Number of stops of the train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------------------+-------------------------+--------------+-----------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+-----------+------------+\n",
      "|train_class|train_number|train_arrival_stop_name|train_departure_stop_name|     stop_name|avg_arrival_delay|median_arrival_delay|count_dates_stop|first_date| last_date|count_3m_delay|count_5m_delay|count_10m_delay| stop_lat| stop_lon|stop_time|count_dates_train|stop_number|    train_id|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------+-----------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+-----------+------------+\n",
      "|         IC|        1962|        MILANO CENTRALE|                 SIRACUSA|ROMA TIBURTINA|7.526315789473684|                 3.0|              19|2023-01-06|2023-03-31|            11|             9|              8|41.910903|12.530749|    02:43|               23|          1|687194767405|\n",
      "+-----------+------------+-----------------------+-------------------------+--------------+-----------------+--------------------+----------------+----------+----------+--------------+--------------+---------------+---------+---------+---------+-----------------+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trains_stat3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to elaborate some general stastistics about a train, and store a dataset which is an index of the train ids, and the statistics of that train.\n",
    "\n",
    "# The aggregated statistics that we want to store are: \n",
    "# 1. Average arrival delay at each destination\n",
    "# 2. Median arrival delay at each destination\n",
    "# 3. % of trains with delay > 3 at each destination\n",
    "# 4. % of trains with delay > 5 at each destination\n",
    "# 5. % of trains with delay > 10 at each destination\n",
    "# 6. Number of days the train ran\n",
    "# 7. Number of stops of the train\n",
    "\n",
    "\n",
    "df_trains_stat4 = df_trains_stat3 \\\n",
    "    .groupBy(\"train_id\", \"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\") \\\n",
    "    .agg(\n",
    "        F.avg(\"avg_arrival_delay\").alias(\"avg_arrival_delay\"),\n",
    "        F.avg(\"median_arrival_delay\").alias(\"median_arrival_delay\"),\n",
    "        (F.avg(\"count_3m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_3m_delay\"),\n",
    "        (F.avg(\"count_5m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_5m_delay\"),\n",
    "        (F.avg(\"count_10m_delay\") / F.first(\"count_dates_train\")).alias(\"perc_10m_delay\"),\n",
    "        F.first(\"count_dates_train\").alias(\"count_dates_train\"),\n",
    "        F.countDistinct(\"stop_name\").alias(\"count_stops_train\"),\n",
    "        F.first(\"first_date\").alias(\"first_date\"),\n",
    "        F.first(\"last_date\").alias(\"last_date\"),\n",
    "        F.min(\"stop_time\").alias(\"departure_time\"),\n",
    "        F.max(\"stop_time\").alias(\"arrival_time\"),\n",
    "    ) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trains_stat4_pandas = df_trains_stat4.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_class</th>\n",
       "      <th>train_number</th>\n",
       "      <th>train_departure_stop_name</th>\n",
       "      <th>train_arrival_stop_name</th>\n",
       "      <th>avg_arrival_delay</th>\n",
       "      <th>median_arrival_delay</th>\n",
       "      <th>perc_3m_delay</th>\n",
       "      <th>perc_5m_delay</th>\n",
       "      <th>perc_10m_delay</th>\n",
       "      <th>count_dates_train</th>\n",
       "      <th>count_stops_train</th>\n",
       "      <th>first_date</th>\n",
       "      <th>last_date</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34359738418</td>\n",
       "      <td>FR</td>\n",
       "      <td>9328</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>MANTOVA</td>\n",
       "      <td>2.597628</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.365646</td>\n",
       "      <td>0.221088</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>84</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>19:25</td>\n",
       "      <td>23:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94489280513</td>\n",
       "      <td>REG</td>\n",
       "      <td>4096</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>FIRENZE S.M.N.</td>\n",
       "      <td>4.621205</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.281656</td>\n",
       "      <td>0.134740</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>07:02</td>\n",
       "      <td>10:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137438953510</td>\n",
       "      <td>REG</td>\n",
       "      <td>2116</td>\n",
       "      <td>GENOVA P.PRINCIPE</td>\n",
       "      <td>TORINO P.NUOVA</td>\n",
       "      <td>1.689368</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>06:27</td>\n",
       "      <td>08:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154618822669</td>\n",
       "      <td>REG</td>\n",
       "      <td>10676</td>\n",
       "      <td>PAVIA</td>\n",
       "      <td>VERCELLI</td>\n",
       "      <td>3.627299</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.219697</td>\n",
       "      <td>0.032197</td>\n",
       "      <td>88</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>12:38</td>\n",
       "      <td>14:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188978561024</td>\n",
       "      <td>REG</td>\n",
       "      <td>827</td>\n",
       "      <td>M N CADORNA</td>\n",
       "      <td>SARONNO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>09:47</td>\n",
       "      <td>10:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>206158430238</td>\n",
       "      <td>REG</td>\n",
       "      <td>3211</td>\n",
       "      <td>TORINO P.NUOVA</td>\n",
       "      <td>CUNEO</td>\n",
       "      <td>4.411054</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.303371</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>89</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>05:25</td>\n",
       "      <td>06:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>223338299438</td>\n",
       "      <td>REG</td>\n",
       "      <td>23209</td>\n",
       "      <td>MONTEBELLUNA</td>\n",
       "      <td>PADOVA</td>\n",
       "      <td>1.715833</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-02-27</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>09:46</td>\n",
       "      <td>10:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>274877906981</td>\n",
       "      <td>REG</td>\n",
       "      <td>3874</td>\n",
       "      <td>TRIESTE CENTRALE</td>\n",
       "      <td>VENEZIA SANTA LUCIA</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0.096124</td>\n",
       "      <td>0.024031</td>\n",
       "      <td>86</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>06:58</td>\n",
       "      <td>09:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>292057776134</td>\n",
       "      <td>REG</td>\n",
       "      <td>4640</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>FIUMICINO AEROPORTO</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.073864</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>15:35</td>\n",
       "      <td>16:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>386547056691</td>\n",
       "      <td>REG</td>\n",
       "      <td>20214</td>\n",
       "      <td>COLLEFERRO-SEGNI-PALIANO</td>\n",
       "      <td>ROMA TERMINI</td>\n",
       "      <td>0.820789</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.118280</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>19:15</td>\n",
       "      <td>20:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_id train_class train_number train_departure_stop_name  \\\n",
       "0   34359738418          FR         9328              ROMA TERMINI   \n",
       "1   94489280513         REG         4096              ROMA TERMINI   \n",
       "2  137438953510         REG         2116         GENOVA P.PRINCIPE   \n",
       "3  154618822669         REG        10676                     PAVIA   \n",
       "4  188978561024         REG          827               M N CADORNA   \n",
       "5  206158430238         REG         3211            TORINO P.NUOVA   \n",
       "6  223338299438         REG        23209              MONTEBELLUNA   \n",
       "7  274877906981         REG         3874          TRIESTE CENTRALE   \n",
       "8  292057776134         REG         4640              ROMA TERMINI   \n",
       "9  386547056691         REG        20214  COLLEFERRO-SEGNI-PALIANO   \n",
       "\n",
       "  train_arrival_stop_name  avg_arrival_delay  median_arrival_delay  \\\n",
       "0                 MANTOVA           2.597628              0.571429   \n",
       "1          FIRENZE S.M.N.           4.621205              1.071429   \n",
       "2          TORINO P.NUOVA           1.689368             -0.875000   \n",
       "3                VERCELLI           3.627299              2.500000   \n",
       "4                 SARONNO           0.000000              0.000000   \n",
       "5                   CUNEO           4.411054              2.625000   \n",
       "6                  PADOVA           1.715833              1.250000   \n",
       "7     VENEZIA SANTA LUCIA           0.700000             -0.333333   \n",
       "8     FIUMICINO AEROPORTO           0.039773             -0.500000   \n",
       "9            ROMA TERMINI           0.820789              0.555556   \n",
       "\n",
       "   perc_3m_delay  perc_5m_delay  perc_10m_delay count_dates_train  \\\n",
       "0       0.365646       0.221088        0.086735                84   \n",
       "1       0.441558       0.281656        0.134740                88   \n",
       "2       0.166667       0.104167        0.058333                30   \n",
       "3       0.593750       0.219697        0.032197                88   \n",
       "4       0.000000       0.000000        0.000000                88   \n",
       "5       0.567416       0.303371        0.084270                89   \n",
       "6       0.390000       0.130000        0.000000                25   \n",
       "7       0.190698       0.096124        0.024031                86   \n",
       "8       0.073864       0.022727        0.011364                88   \n",
       "9       0.118280       0.008961        0.000000                62   \n",
       "\n",
       "   count_stops_train  first_date   last_date departure_time arrival_time  \n",
       "0                  7  2023-01-02  2023-03-31          19:25        23:03  \n",
       "1                 14  2023-01-02  2023-03-31          07:02        10:48  \n",
       "2                  8  2023-01-01  2023-03-26          06:27        08:30  \n",
       "3                 12  2023-01-01  2023-03-31          12:38        14:04  \n",
       "4                  5  2023-01-01  2023-03-31          09:47        10:07  \n",
       "5                  8  2023-01-01  2023-03-31          05:25        06:36  \n",
       "6                  4  2023-02-27  2023-03-31          09:46        10:33  \n",
       "7                 15  2023-01-01  2023-03-31          06:58        09:59  \n",
       "8                  2  2023-01-01  2023-03-31          15:35        16:07  \n",
       "9                  9  2023-01-02  2023-03-31          19:15        20:13  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trains_stat4_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: dataset_generated/data_train_index.csv (deflated 69%)\n"
     ]
    }
   ],
   "source": [
    "if SAVE_COMPUTATIONS :    \n",
    "    # store the file in a csv file  \n",
    "    df_trains_stat4_pandas.to_csv(\"dataset_generated/data_train_index.csv\", index=False)\n",
    "\n",
    "    # zip the file\n",
    "    !zip dataset_generated/data_train_index.zip dataset_generated/data_train_index.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we store the data in a better format, which is a folder in which each file is a train, and the filename is the train id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# if the folder already exists, delete it\n",
    "if os.path.exists(\"renamed_csv_files\"):\n",
    "    shutil.rmtree(\"renamed_csv_files\")\n",
    "\n",
    "# create a new directory to store the renamed CSV files\n",
    "if not os.path.exists(\"renamed_csv_files\"):\n",
    "    os.mkdir(\"renamed_csv_files\")\n",
    "\n",
    "# loop through all directories in the \"data_train_stat/data_train_stat.csv\" directory that start with \"train_id=\"\n",
    "for dirpath, dirnames, filenames in os.walk(\"dataset_generated/data_train_stat/data_train_stat.csv\"):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith(\"train_id=\"):\n",
    "            # extract the ID from the directory name\n",
    "            id = dirname.split(\"=\")[1]\n",
    "            # loop through all CSV files in the directory\n",
    "            for filename in os.listdir(os.path.join(dirpath, dirname)):\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    # rename the file to \"[ID].csv\" and move it to the \"renamed_csv_files\" directory\n",
    "                    src_path = os.path.join(dirpath, dirname, filename)\n",
    "                    dst_path = os.path.join(\"renamed_csv_files\", f\"{id}.csv\")\n",
    "                    shutil.copy(src_path, dst_path)\n",
    "\n",
    "\n",
    "# create a zip file containing the \"renamed_csv_files\" directory, the files have to be in a directory when unzipped\n",
    "shutil.make_archive(\"renamed_csv_files\", \"zip\", \"renamed_csv_files\")\n",
    "\n",
    "# delete the \"renamed_csv_files\" directory\n",
    "shutil.rmtree(\"renamed_csv_files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Path of trains over a map\n",
    "Now that we have computed a dataset with the statistics for each train, in which we managed to extract the timetable, we can use it to plot the path of each train on a map. \n",
    "\n",
    "The task of matching information of a train, with its exact journey on the railway is a complex task. The algorithm developed by [Bast and Brosi (2019)](https://ad-publications.cs.uni-freiburg.de/SIGSPATIAL_Sparse%20map%20matching%202018.pdf) matches the GTFS schedule of a train with the OpenStreetMap railway network. Thankfully, they published the code of this algorithm on GitHub. Their library takes a GTFS schedule of a train and a railway network in OpenStreetMap format and returns the most likely journey of the train on the railway network in `shapefile` format. GTFS is a standard format for public transport schedules, promoted by Google.\n",
    "\n",
    "First, we need to generate a GTFS timetable for our trains. Then, we can run the algorithm a produce a shapefile for each train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trains_timetable = df_trains_stat3 \\\n",
    "    .select(\"train_id\", \"train_class\", \"train_number\", \"train_departure_stop_name\", \"train_arrival_stop_name\", \"stop_number\", \"stop_name\", \"stop_time\", \"stop_lat\", \"stop_lon\")\n",
    "\n",
    "# need to join with the stops to get stop_id that we have lost on the way\n",
    "trains_timetable = trains_timetable \\\n",
    "    .join(stops, on=[\"stop_name\", \"stop_lat\", \"stop_lon\"], how=\"inner\")\n",
    "\n",
    "trains_timetable_pandas = trains_timetable.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>train_id</th>\n",
       "      <th>train_class</th>\n",
       "      <th>train_number</th>\n",
       "      <th>train_departure_stop_name</th>\n",
       "      <th>train_arrival_stop_name</th>\n",
       "      <th>stop_number</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name_short</th>\n",
       "      <th>stop_id_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROMA TIBURTINA</td>\n",
       "      <td>41.910903</td>\n",
       "      <td>12.530749</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>1</td>\n",
       "      <td>02:43</td>\n",
       "      <td>S08217</td>\n",
       "      <td>Roma Tiburtina</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIRENZE CAMPO MARTE</td>\n",
       "      <td>43.776856</td>\n",
       "      <td>11.27702</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>2</td>\n",
       "      <td>05:36</td>\n",
       "      <td>S06900</td>\n",
       "      <td>Firenze C.Marte</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRATO CENTRALE</td>\n",
       "      <td>43.878737</td>\n",
       "      <td>11.109252</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>3</td>\n",
       "      <td>06:04</td>\n",
       "      <td>S06416</td>\n",
       "      <td>Prato C.Le</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PISA CENTRALE</td>\n",
       "      <td>43.70794</td>\n",
       "      <td>10.398183</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>4</td>\n",
       "      <td>06:47</td>\n",
       "      <td>S06500</td>\n",
       "      <td>Pisa Centrale</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOLOGNA C.LE</td>\n",
       "      <td>44.50626</td>\n",
       "      <td>11.342267</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>5</td>\n",
       "      <td>07:07</td>\n",
       "      <td>S05043</td>\n",
       "      <td>Bologna Centrale</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VIAREGGIO</td>\n",
       "      <td>43.865947</td>\n",
       "      <td>10.257886</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>6</td>\n",
       "      <td>07:11</td>\n",
       "      <td>S06040</td>\n",
       "      <td>Viareggio</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MODENA</td>\n",
       "      <td>44.654461</td>\n",
       "      <td>10.930373</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>7</td>\n",
       "      <td>07:41</td>\n",
       "      <td>S05032</td>\n",
       "      <td>Modena</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>REGGIO EMILIA</td>\n",
       "      <td>44.697793</td>\n",
       "      <td>10.643093</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>8</td>\n",
       "      <td>08:04</td>\n",
       "      <td>S05023</td>\n",
       "      <td>Reggio Emilia</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LA SPEZIA CENTRALE</td>\n",
       "      <td>44.11141</td>\n",
       "      <td>9.813906</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>9</td>\n",
       "      <td>08:07</td>\n",
       "      <td>S06000</td>\n",
       "      <td>La Spezia C.le</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PARMA</td>\n",
       "      <td>44.810203</td>\n",
       "      <td>10.32837</td>\n",
       "      <td>687194767405</td>\n",
       "      <td>IC</td>\n",
       "      <td>1962</td>\n",
       "      <td>SIRACUSA</td>\n",
       "      <td>MILANO CENTRALE</td>\n",
       "      <td>10</td>\n",
       "      <td>08:21</td>\n",
       "      <td>S05014</td>\n",
       "      <td>Parma</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             stop_name   stop_lat   stop_lon      train_id train_class  \\\n",
       "0       ROMA TIBURTINA  41.910903  12.530749  687194767405          IC   \n",
       "1  FIRENZE CAMPO MARTE  43.776856   11.27702  687194767405          IC   \n",
       "2       PRATO CENTRALE  43.878737  11.109252  687194767405          IC   \n",
       "3        PISA CENTRALE   43.70794  10.398183  687194767405          IC   \n",
       "4         BOLOGNA C.LE   44.50626  11.342267  687194767405          IC   \n",
       "5            VIAREGGIO  43.865947  10.257886  687194767405          IC   \n",
       "6               MODENA  44.654461  10.930373  687194767405          IC   \n",
       "7        REGGIO EMILIA  44.697793  10.643093  687194767405          IC   \n",
       "8   LA SPEZIA CENTRALE   44.11141   9.813906  687194767405          IC   \n",
       "9                PARMA  44.810203   10.32837  687194767405          IC   \n",
       "\n",
       "  train_number train_departure_stop_name train_arrival_stop_name stop_number  \\\n",
       "0         1962                  SIRACUSA         MILANO CENTRALE           1   \n",
       "1         1962                  SIRACUSA         MILANO CENTRALE           2   \n",
       "2         1962                  SIRACUSA         MILANO CENTRALE           3   \n",
       "3         1962                  SIRACUSA         MILANO CENTRALE           4   \n",
       "4         1962                  SIRACUSA         MILANO CENTRALE           5   \n",
       "5         1962                  SIRACUSA         MILANO CENTRALE           6   \n",
       "6         1962                  SIRACUSA         MILANO CENTRALE           7   \n",
       "7         1962                  SIRACUSA         MILANO CENTRALE           8   \n",
       "8         1962                  SIRACUSA         MILANO CENTRALE           9   \n",
       "9         1962                  SIRACUSA         MILANO CENTRALE          10   \n",
       "\n",
       "  stop_time stop_id   stop_name_short  stop_id_region  \n",
       "0     02:43  S08217    Roma Tiburtina             5.0  \n",
       "1     05:36  S06900   Firenze C.Marte            13.0  \n",
       "2     06:04  S06416        Prato C.Le            13.0  \n",
       "3     06:47  S06500     Pisa Centrale            13.0  \n",
       "4     07:07  S05043  Bologna Centrale             8.0  \n",
       "5     07:11  S06040         Viareggio            13.0  \n",
       "6     07:41  S05032            Modena             8.0  \n",
       "7     08:04  S05023     Reggio Emilia             8.0  \n",
       "8     08:07  S06000    La Spezia C.le             2.0  \n",
       "9     08:21  S05014             Parma             8.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains_timetable_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# delete folder if it exists\n",
    "import shutil\n",
    "if os.path.exists(\"gtfs\"):\n",
    "    shutil.rmtree(\"gtfs\")\n",
    "\n",
    "# create folder gtfs \n",
    "if not os.path.exists(\"gtfs\"):\n",
    "    os.mkdir(\"gtfs\")\n",
    "\n",
    "# 1. Create the agency.txt file\n",
    "agency = {\n",
    "    \"agency_id\": \"1\",\n",
    "    \"agency_name\": \"Trenitalia\",\n",
    "    \"agency_url\": \"https://www.trenitalia.com\",\n",
    "    \"agency_timezone\": \"Europe/Rome\",\n",
    "    \"agency_lang\": \"it\",\n",
    "    \"agency_phone\": \"\"\n",
    "}\n",
    "agency = pd.DataFrame(agency, index=[0])\n",
    "agency.to_csv(\"gtfs/agency.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39magency_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39mroute_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# 2 is train\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39mroute_color\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m routes[\u001b[39m\"\u001b[39;49m\u001b[39mroute_short_name\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: color_mapper[x\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m0\u001b[39;49m]])\n\u001b[1;32m     30\u001b[0m routes\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mgtfs/routes.txt\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TrenitaliaSpark/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TrenitaliaSpark/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TrenitaliaSpark/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/TrenitaliaSpark/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[119], line 28\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39magency_id\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39mroute_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m2\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# 2 is train\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m routes[\u001b[39m\"\u001b[39m\u001b[39mroute_color\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m routes[\u001b[39m\"\u001b[39m\u001b[39mroute_short_name\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: color_mapper[x\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]])\n\u001b[1;32m     30\u001b[0m routes\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mgtfs/routes.txt\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# 2. create routes.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#routestxt\n",
    "\n",
    "\n",
    "routes = pd.DataFrame()\n",
    "\n",
    "# get unique tuples (train_id, train_class, train_number)\n",
    "train_ids = trains_timetable_pandas[[\"train_id\", \"train_class\", \"train_number\"]].drop_duplicates()\n",
    "\n",
    "routes[\"route_id\"] = train_ids[\"train_id\"]\n",
    "routes[\"route_short_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "routes[\"route_long_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "\n",
    "color_mapper = {\n",
    "    \"IC\": \"E0A434\",\n",
    "    \"REG\": \"036864\",\n",
    "    \"ICN\": \"E0A434\",\n",
    "    \"AV\": \"DC263B\",\n",
    "    \"EC\": \"DC263B\",\n",
    "    \"FR\": \"DC263B\",\n",
    "    \"FA\": \"DC263B\",\n",
    "    \"FB\": \"DC263B\",\n",
    "}\n",
    "\n",
    "routes[\"agency_id\"] = \"1\"\n",
    "routes[\"route_type\"] = \"2\" # 2 is train\n",
    "\n",
    "routes[\"route_color\"] = routes[\"route_short_name\"].apply(lambda x: color_mapper[x.split(\" \")[0]])\n",
    "\n",
    "routes.to_csv(\"gtfs/routes.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. create stops.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#stopstxt\n",
    "stops_gtfs = trains_timetable_pandas[[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\"]].drop_duplicates()\n",
    "stops_gtfs.to_csv(\"gtfs/stops.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Tough one, create calendar.txt and trips.txt\n",
    "# calendar describes the span of a service\n",
    "# trips describes the service for a particular route\n",
    "\n",
    "# 4a: create calendar.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#calendartxt\n",
    "calendar = {\n",
    "    # we just create a service that runs every day for the whole year\n",
    "    \"service_id\": \"1\",\n",
    "    \"monday\": \"1\",\n",
    "    \"tuesday\": \"1\",\n",
    "    \"wednesday\": \"1\",\n",
    "    \"thursday\": \"1\",\n",
    "    \"friday\": \"1\",\n",
    "    \"saturday\": \"1\",\n",
    "    \"sunday\": \"1\",\n",
    "    \"start_date\": \"19000101\",\n",
    "    \"end_date\": \"21000101\",\n",
    "}\n",
    "calendar = pd.DataFrame(calendar, index=[0])\n",
    "calendar.to_csv(\"gtfs/calendar.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b: create trips.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#tripstxt\n",
    "# trips = {\n",
    "#     \"route_id\": \"1\",\n",
    "#     \"service_id\": \"1\",\n",
    "#     \"trip_id\": \"1\",\n",
    "#     \"trip_headsign\": query_7[\"train_class\"] + \" \" + query_7[\"train_number\"],\n",
    "#     \"trip_short_name\": query_7[\"train_class\"] + \" \" + query_7[\"train_number\"],\n",
    "#     \"direction_id\": \"\",\n",
    "#     \"block_id\": \"\",\n",
    "#     \"shape_id\": \"\",\n",
    "#     \"wheelchair_accessible\": \"\",\n",
    "#     \"bikes_allowed\": \"\",\n",
    "# }\n",
    "\n",
    "# trips = pd.DataFrame(trips, index=[0])\n",
    "\n",
    "trips = pd.DataFrame()\n",
    "\n",
    "trips[\"route_id\"] = train_ids[\"train_id\"]\n",
    "trips[\"service_id\"] = \"1\"\n",
    "trips[\"trip_id\"] = train_ids[\"train_id\"]\n",
    "trips[\"trip_headsign\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "trips[\"trip_short_name\"] = train_ids[\"train_class\"] + \" \" + train_ids[\"train_number\"]\n",
    "trips[\"direction_id\"] = \"\"\n",
    "trips[\"block_id\"] = \"\"\n",
    "trips[\"shape_id\"] = \"\"\n",
    "trips[\"wheelchair_accessible\"] = \"\"\n",
    "trips[\"bikes_allowed\"] = \"\"\n",
    "\n",
    "\n",
    "trips.to_csv(\"gtfs/trips.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains_timetable_pandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create stop_times.txt\n",
    "# docs: https://gtfs.org/schedule/reference/#stop_timestxt\n",
    "# convert stop_departure_time to HH:MM:SS using pyspark function\n",
    "\n",
    "# stop_times: pd.DataFrame = train_data_day_df[[\"stop_id\", \"stop_departure_time\", \"stop_arrival_time\"]] \\\n",
    "#     .rename(columns={\"stop_id\": \"stop_id\", \"stop_departure_time\": \"departure_time\", \"stop_arrival_time\": \"arrival_time\"})\n",
    "\n",
    "\n",
    "# def convert_to_hh_mm_ss(time):\n",
    "    \n",
    "                                                                                                            \n",
    "# # add column with stop_sequence\n",
    "# stop_times[\"stop_sequence\"] = stop_times.index + 1\n",
    "# # add column with trip_id\n",
    "# stop_times[\"trip_id\"] = \"1\"\n",
    "# # put departure time of the last stop equal to the arrival time\n",
    "# stop_times.loc[stop_times.index[-1], \"departure_time\"] = stop_times.loc[stop_times.index[-1], \"arrival_time\"]\n",
    "# store it\n",
    "\n",
    "stop_times_gtfs = pd.DataFrame()\n",
    "\n",
    "stop_times_gtfs[\"trip_id\"] = trains_timetable_pandas[\"train_id\"]\n",
    "stop_times_gtfs[\"arrival_time\"] = trains_timetable_pandas[\"stop_time\"].apply(lambda x: x + \":00\")\n",
    "stop_times_gtfs[\"departure_time\"] = trains_timetable_pandas[\"stop_time\"].apply(lambda x: x + \":00\")\n",
    "stop_times_gtfs[\"stop_id\"] = trains_timetable_pandas[\"stop_id\"]\n",
    "stop_times_gtfs[\"stop_sequence\"] = trains_timetable_pandas[\"stop_number\"]\n",
    "\n",
    "stop_times_gtfs.to_csv(\"gtfs/stop_times.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a zip using libzip\n",
    "import zipfile\n",
    "zf = zipfile.ZipFile('gtfs.zip', mode='w')\n",
    "try:\n",
    "    zf.write(\"gtfs/agency.txt\")\n",
    "    zf.write(\"gtfs/calendar.txt\")\n",
    "    zf.write(\"gtfs/routes.txt\")\n",
    "    zf.write(\"gtfs/stops.txt\")\n",
    "    zf.write(\"gtfs/stop_times.txt\")\n",
    "    zf.write(\"gtfs/trips.txt\")\n",
    "finally:\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the algorithm\n",
    "We downloaded and installed pfaedle as well as an OSM dump for Italy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current folder name\n",
    "# import os\n",
    "# os.path.basename(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pfaedle -x ~/Downloads/italy-latest.osm {}\"\"\".format(os.path.join(os.getcwd(), \"gtfs\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the shapes in the \"shapes.txt\" file, we want to separate all those files into one file for each train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "shapes_gtfs = pd.read_csv(\"gtfs-out/shapes.txt\")\n",
    "trips_gtfs = pd.read_csv(\"gtfs-out/trips.txt\")\n",
    "\n",
    "shapes_gtfs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_gtfs = trips_gtfs[[\"trip_id\",\"shape_id\"]]\n",
    "# merge columns on shape_id\n",
    "shapes_gtfs_merged = shapes_gtfs.merge(trips_gtfs, on=\"shape_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop shape_id\n",
    "print(\"The number of distinct trains is \", shapes_gtfs_merged[\"trip_id\"].nunique(), \"while the number of distinct shapes is \", shapes_gtfs_merged[\"shape_id\"].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could save some space by storing the shapes independently from the trains, since there's multiple trains that share the same shape. However, to keep the frontend of the website simple, we decided to store the shape of each train in a separated file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(shapes_gtfs_merged[\"trip_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# delete folder if exists\n",
    "import shutil\n",
    "if os.path.exists(\"dataset_generated/trains_shapes\"):\n",
    "    shutil.rmtree(\"dataset_generated/trains_shapes\")\n",
    "\n",
    "# create folder\n",
    "os.mkdir(\"dataset_generated/trains_shapes\")\n",
    "\n",
    "# for each trid_id, save all the corrisponding shapes in a file\n",
    "for trip_id in tqdm(pd.unique(shapes_gtfs_merged[\"trip_id\"])):\n",
    "    shapes_gtfs_merged[shapes_gtfs_merged[\"trip_id\"] == trip_id][[\"shape_pt_lat\", \"shape_pt_lon\"]].to_csv(\"dataset_generated/trains_shapes/{}.csv\".format(trip_id), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the folder with shutil\n",
    "shutil.make_archive(\"dataset_generated/trains_shapes\", 'zip', \"dataset_generated/trains_shapes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrenitaliaSpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
